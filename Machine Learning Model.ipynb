{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentails \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RepeatedStratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Saving the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "# Load the testing dataset\n",
    "test = pd.read_csv('testing_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matrix and Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response variable\n",
    "y = train['Survived'].values\n",
    "\n",
    "# Feature matrix\n",
    "X = train.drop('Survived', axis=1).values\n",
    "\n",
    "# Splitting the data into training and cross validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    \n",
    "    print('Accuarcy:', accuracy_score(y_true, y_pred))\n",
    "    print('Sensitivity:', recall_score(y_true, y_pred))\n",
    "    print('Specificity:', TN / (TN + FP))\n",
    "    print('False Positive Rate:', FP / (TN + FP))\n",
    "    print('Precision:', precision_score(y_true, y_pred))\n",
    "    print('F1 Score:', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(['Accuarcy', 'Sensitivity', 'Specificity', 'FPR', 'Precision', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.columns = ['Metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model_to_df(y_true, y_pred, dataframe, modelName):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    \n",
    "    accuarcy = accuracy_score(y_true, y_pred)\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    specificity = TN / (TN + FP)\n",
    "    fpr = FP / (TN + FP)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    dataframe[modelName] = np.array([accuarcy, sensitivity, specificity, fpr, precision, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "max_iter = list(range(100,500,100))\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameter names to the values that need to be searched\n",
    "param_dict = dict(C=C, penalty=penalty, max_iter=max_iter, solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Default): 0.8073552425665103\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the LogisticRegression model using the default parameters\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# 10-fold stratified cross-validation with 3 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# Evaluate the accuarcy of the naive model using cross-validation \n",
    "scores = cross_val_score(logreg, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Default):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'max_iter': [100, 200, 300, 400],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid\n",
    "grid_logreg = GridSearchCV(logreg, param_dict, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid to the training data\n",
    "grid_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8073552425665103\n",
      "{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Best model score and parameters\n",
    "print(grid_logreg.best_score_)\n",
    "print(grid_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Tuned): 0.8073552425665103\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the logistic regression model using the best known parameters\n",
    "logreg = LogisticRegression(C=1, max_iter=100, penalty='l2', solver='saga', random_state=42)\n",
    "\n",
    "# Evaluate the accuracy of the tuned model using cross-validation\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Tuned):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the logistic regression model on the training data, using the best known parameters\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the hold out set, since they are truly out of sample  \n",
    "y_pred = logreg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.8033707865168539\n",
      "Sensitivity: 0.7352941176470589\n",
      "Specificity: 0.8454545454545455\n",
      "False Positive Rate: 0.15454545454545454\n",
      "Precision: 0.746268656716418\n",
      "F1 Score: 0.7407407407407408\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the hold out set predictions  \n",
    "evaluate_model(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model_to_df(y_val, y_pred, models, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDG Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Default): 0.7534298382889932\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SGDClassifier model using the default parameters\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "\n",
    "# 10-fold stratified cross-validation with 3 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# Evaluate the accuarcy of the naive model using cross-validation \n",
    "scores = cross_val_score(sgd, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Default):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "loss = ['hinge', 'log', 'squared_hinge', 'modified_huber']\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "penalty = ['l1', 'l2', 'none', 'elasticnet']\n",
    "l1_ratio = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "max_iter = list(range(200,2000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameter names to the values that need to be searched\n",
    "param_dict = dict(loss=loss, alpha=alpha, penalty=penalty, l1_ratio=l1_ratio, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=SGDClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
       "                         'loss': ['hinge', 'log', 'squared_hinge',\n",
       "                                  'modified_huber'],\n",
       "                         'max_iter': [200, 400, 600, 800, 1000, 1200, 1400,\n",
       "                                      1600, 1800],\n",
       "                         'penalty': ['l1', 'l2', 'none', 'elasticnet']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid\n",
    "grid_sgd = GridSearchCV(sgd, param_dict, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid to the training data\n",
    "grid_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804518779342723\n",
      "{'alpha': 0.01, 'l1_ratio': 0.1, 'loss': 'log', 'max_iter': 200, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Best model score and parameters\n",
    "print(grid_sgd.best_score_)\n",
    "print(grid_sgd.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Tuned): 0.804518779342723\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SGDClassifier model using the best known parameters\n",
    "sgd = SGDClassifier(alpha=0.01, l1_ratio=0.1, loss='log', max_iter=200, penalty='l2', random_state=42)\n",
    "\n",
    "# Evaluate the accuracy of the tuned model using cross-validation\n",
    "scores = cross_val_score(sgd, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Tuned):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the stochastic gradient classifier on the training data, using the best known parameters\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the hold out set, since they are truly out of sample  \n",
    "y_pred = sgd.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.7808988764044944\n",
      "Sensitivity: 0.75\n",
      "Specificity: 0.8\n",
      "False Positive Rate: 0.2\n",
      "Precision: 0.6986301369863014\n",
      "F1 Score: 0.7234042553191489\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the hold out set predictions  \n",
    "evaluate_model(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model_to_df(y_val, y_pred, models, 'SGD Classfier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.8256194574856547\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GradientBoostingClassifier  model using the default parameters\n",
    "grad = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# 10-fold stratified cross-validation with 3 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# Evaluate the accuarcy of the naive model using cross-validation \n",
    "scores = cross_val_score(grad, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Average Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "loss = ['deviance', 'exponential']\n",
    "learning_rate = [0.001, 0.01, 0.1, 1]\n",
    "n_estimators = [50, 100, 200, 400, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameter names to the values that need to be searched\n",
    "param_dict = dict(max_features=max_features, loss=loss, learning_rate=learning_rate, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=GradientBoostingClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 1],\n",
       "                         'loss': ['deviance', 'exponential'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100, 200, 400, 800]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid\n",
    "grid_grad = GridSearchCV(grad, param_dict, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid to the training data\n",
    "grid_grad.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327073552425664\n",
      "{'learning_rate': 0.1, 'loss': 'deviance', 'max_features': 'sqrt', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Best model score and parameters\n",
    "print(grid_grad.best_score_)\n",
    "print(grid_grad.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Tuned): 0.8327073552425664\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GradientBoostingClassifier model using the best known parameters\n",
    "grad = GradientBoostingClassifier(learning_rate=0.1, loss='deviance', max_features='sqrt', n_estimators=400, random_state=42)\n",
    "\n",
    "# Evaluate the accuracy of the tuned model using cross-validation\n",
    "scores = cross_val_score(grad, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Tuned):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the gradient boosting classifier on the training data, using the best known parameters\n",
    "grad.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the hold out set, since they are truly out of sample  \n",
    "y_pred = grad.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.8258426966292135\n",
      "Sensitivity: 0.7352941176470589\n",
      "Specificity: 0.8818181818181818\n",
      "False Positive Rate: 0.11818181818181818\n",
      "Precision: 0.7936507936507936\n",
      "F1 Score: 0.7633587786259542\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the hold out set predictions  \n",
    "evaluate_model(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model_to_df(y_val, y_pred, models, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Default): 0.7839136671883152\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the DecisionTreeClassifier  model using the default parameters\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 10-fold stratified cross-validation with 3 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# Evaluate the accuarcy of the naive model using cross-validation \n",
    "scores = cross_val_score(tree, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Default):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = list(range(1, 10))\n",
    "min_samples_split = list(range(1, 10))\n",
    "min_samples_leaf = list(range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameter names to the values that need to be searched\n",
    "param_dict = dict(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4],\n",
       "                         'min_samples_split': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid\n",
    "grid_tree = GridSearchCV(tree, param_dict, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid to the training data\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8293883672404797\n",
      "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Best model score and parameters\n",
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Tuned): 0.8293883672404797\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the DecisionTreeClassifier  model using the best known parameters\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=1, min_samples_split=2, random_state=42)\n",
    "\n",
    "# Evaluate the accuracy of the tuned model using cross-validation\n",
    "scores = cross_val_score(tree, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Accuracy (Tuned):', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the decision tree classifier on the training data, using the best known parameters\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the hold out set, since they are truly out of sample  \n",
    "y_pred = tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.8146067415730337\n",
      "Sensitivity: 0.7058823529411765\n",
      "Specificity: 0.8818181818181818\n",
      "False Positive Rate: 0.11818181818181818\n",
      "Precision: 0.7868852459016393\n",
      "F1 Score: 0.7441860465116278\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the hold out set predictions  \n",
    "evaluate_model(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model_to_df(y_val, y_pred, models, 'Decision Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.804094940010433\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the KNeighborsClassifier model using the default parameters\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 10-fold stratified cross-validation with 3 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# Evaluate the accuarcy of the naive model using cross-validation \n",
    "scores = cross_val_score(knn, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Average Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameter names to the values that need to be searched\n",
    "param_dict = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                       23, 24, 25, 26, 27, 28, 29, 30, ...],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29],\n",
       "                         'p': [1, 2]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid\n",
    "grid_knn = GridSearchCV(knn, param_dict, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid to the training data\n",
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8251369327073552\n",
      "{'leaf_size': 1, 'n_neighbors': 15, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "# Best model score and parameters\n",
    "print(grid_knn.best_score_)\n",
    "print(grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.8251369327073552\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the KNeighborsClassifier model using the best known parameters\n",
    "knn = KNeighborsClassifier(leaf_size=1, n_neighbors=15, p=1)\n",
    "\n",
    "# Evaluate the accuracy of the tuned model using cross-validation\n",
    "scores = cross_val_score(knn, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Average Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the knn classifier on the training data, using the best known parameters\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the hold out set, since they are truly out of sample  \n",
    "y_pred = knn.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.8033707865168539\n",
      "Sensitivity: 0.6029411764705882\n",
      "Specificity: 0.9272727272727272\n",
      "False Positive Rate: 0.07272727272727272\n",
      "Precision: 0.8367346938775511\n",
      "F1 Score: 0.7008547008547009\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the hold out set predictions  \n",
    "evaluate_model(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model_to_df(y_val, y_pred, models, 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.8176317162232656\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SVC(Support Vector Classifier) model using the default parameters\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# 10-fold stratified cross-validation with 3 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# Evaluate the accuarcy of the naive model using cross-validation \n",
    "scores = cross_val_score(svc, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print('Average Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that need to be searched\n",
    "C = [0.001, 0.01, 0.1, 1, 3, 5, 10]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "gamma = ['scale', 'auto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map parameter names to the values that need to be searched\n",
    "param_dict = dict(C=C, gamma=gamma, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 3, 5, 10],\n",
       "                         'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the grid\n",
    "grid_svc = GridSearchCV(svc, param_dict, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid to the training data\n",
    "grid_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8279407929055816\n",
      "{'C': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Best model score and parameters\n",
    "print(grid_svc.best_score_)\n",
    "print(grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.8245318352059924\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the SVC(Support Vector Classifier) model using the best known parameters\n",
    "svc = SVC(kernel='rbf', C=3, gamma='scale', random_state=42)\n",
    "\n",
    "# Evaluate the accuracy of the tuned model using cross-validation\n",
    "scores = cross_val_score(svc, X, y, cv=cv, scoring='accuracy')\n",
    "print('Average Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SVC on the training data, using the best known parameters\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the hold out set, since they are truly out of sample  \n",
    "y_pred = svc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.8089887640449438\n",
      "Sensitivity: 0.6176470588235294\n",
      "Specificity: 0.9272727272727272\n",
      "False Positive Rate: 0.07272727272727272\n",
      "Precision: 0.84\n",
      "F1 Score: 0.711864406779661\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the hold out set predictions  \n",
    "evaluate_model(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model_to_df(y_val, y_pred, models, 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.index = ['Accuarcy', 'Sensitivity', 'Specificity', 'FPR', 'Precision', 'F1 Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.drop('Metrics', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD Classfier</th>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.763359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.700855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuarcy  Sensitivity  Specificity       FPR  Precision  \\\n",
       "Logistic Regression  0.803371     0.735294     0.845455  0.154545   0.746269   \n",
       "SGD Classfier        0.780899     0.750000     0.800000  0.200000   0.698630   \n",
       "Gradient Boosting    0.825843     0.735294     0.881818  0.118182   0.793651   \n",
       "Decision Trees       0.814607     0.705882     0.881818  0.118182   0.786885   \n",
       "KNN                  0.803371     0.602941     0.927273  0.072727   0.836735   \n",
       "SVM                  0.808989     0.617647     0.927273  0.072727   0.840000   \n",
       "\n",
       "                     F1 Score  \n",
       "Logistic Regression  0.740741  \n",
       "SGD Classfier        0.723404  \n",
       "Gradient Boosting    0.763359  \n",
       "Decision Trees       0.744186  \n",
       "KNN                  0.700855  \n",
       "SVM                  0.711864  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'App/Models/logreg.pickle', 'wb') as f:\n",
    "    pickle.dump(logreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'App/Models/sgd.pickle', 'wb') as f:\n",
    "    pickle.dump(sgd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'App/Models/grad.pickle', 'wb') as f:\n",
    "    pickle.dump(grad, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'App/Models/tree.pickle', 'wb') as f:\n",
    "    pickle.dump(tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'App/Models/knn.pickle', 'wb') as f:\n",
    "    pickle.dump(knn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'App/Models/svc.pickle', 'wb') as f:\n",
    "    pickle.dump(svc, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
